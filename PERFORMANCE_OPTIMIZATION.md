# PushGuardian ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

## í˜„ìž¬ ë³‘ëª© ë¶„ì„

### ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œê°„ (ì˜ˆìƒ)
```
1. load_config: ~10ms
2. scope_classify: ~50ms
3. hard_policy_check: ~100ms (secrets ê²€ì‚¬)
4. soft_llm_judge: ~2000ms (LLM í˜¸ì¶œ) âš ï¸ ë³‘ëª©
5. research_tavily: ~1500ms (ê²€ìƒ‰ API + LLM annotation) âš ï¸ ë³‘ëª©
6. observation_validate: ~1500ms (LLM í˜¸ì¶œ) âš ï¸ ë³‘ëª©
7. research_serper: ~1500ms (ê²€ìƒ‰ API + LLM annotation) âš ï¸ ë³‘ëª©
8. observation_validate: ~1500ms (LLM í˜¸ì¶œ) âš ï¸ ë³‘ëª©
9. [HITL] research_naver: ~3000ms (LLM ì¿¼ë¦¬ ìƒì„± + ê²€ìƒ‰ + LLM í•„í„°ë§) âš ï¸ ë³‘ëª©
10. write_report: ~500ms (LLM í˜¸ì¶œ)
11. persist_report: ~50ms

ì´: ~12ì´ˆ (HITL ì—†ìœ¼ë©´ ~9ì´ˆ, HITL ìžˆìœ¼ë©´ ~12ì´ˆ)
```

### ì£¼ìš” ë³‘ëª©
1. **LLM í˜¸ì¶œ**: 6-7íšŒ (ê° 1-2ì´ˆ) = ì´ 6-14ì´ˆ
2. **ê²€ìƒ‰ API**: 2-3íšŒ (ê° 0.5-1.5ì´ˆ) = ì´ 1.5-4.5ì´ˆ
3. **ìˆœì°¨ ì‹¤í–‰**: ë³‘ë ¬í™” ê°€ëŠ¥í•œ ìž‘ì—…ë„ ìˆœì°¨ ì‹¤í–‰ ì¤‘

---

## âœ… ìµœì í™” ë°©ì•ˆ

### 1. ì¦‰ì‹œ ì ìš© ê°€ëŠ¥ (Low Hanging Fruit)

#### A. Streamlit sleep ì œê±°
**í˜„ìž¬**: `time.sleep(1)` - ë¶ˆí•„ìš”í•œ 1ì´ˆ ëŒ€ê¸°
**ê°œì„ **: ì œê±°
```python
# streamlit_app.py:189
# time.sleep(1)  # ì œê±°
st.rerun()
```
**íš¨ê³¼**: -1ì´ˆ

#### B. LLM ëª¨ë¸ ìµœì í™”
**í˜„ìž¬**: ëª¨ë“  ê³³ì—ì„œ gpt-4o-mini (ë™ì¼ í’ˆì§ˆ)
**ê°œì„ **: ê°„ë‹¨í•œ ìž‘ì—…ì€ ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
- ë„¤ì´ë²„ ì¿¼ë¦¬ ìƒì„±: gpt-4o-mini â†’ gpt-3.5-turbo (-30%)
- ë„¤ì´ë²„ í•„í„°ë§: gpt-4o-mini ìœ ì§€ (í’ˆì§ˆ ì¤‘ìš”)

**íš¨ê³¼**: -500ms

#### C. ë„¤ì´ë²„ ê²€ìƒ‰ ê°œìˆ˜ ì¤„ì´ê¸°
**í˜„ìž¬**: 10ê°œ ê²€ìƒ‰ â†’ LLM í•„í„°ë§
**ê°œì„ **: 5ê°œ ê²€ìƒ‰ (ì´ë¯¸ 1ì°¨ í•„í„°ë§ìœ¼ë¡œ ì¶©ë¶„)
```python
# graph.py
results = search_naver(query_ko, max_results=5)  # 10 â†’ 5
```
**íš¨ê³¼**: -200ms

---

### 2. ë³‘ë ¬í™” (ì¤‘ê°„ ë‚œì´ë„)

#### A. ê²€ìƒ‰ API ë³‘ë ¬ ì‹¤í–‰
**í˜„ìž¬**: Tavily â†’ Observation â†’ Serper (ìˆœì°¨)
**ê°œì„ **: Tavily + Serper ë™ì‹œ ì‹¤í–‰ â†’ Observation (1íšŒë§Œ)

**êµ¬í˜„**:
```python
# ìƒˆë¡œìš´ ë…¸ë“œ: research_parallel
async def research_parallel_node(state: GuardianState) -> GuardianState:
    """Tavilyì™€ Serperë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰"""
    import asyncio

    async def tavily_search():
        return gather_research(...)

    async def serper_search():
        return gather_research(..., search_engine="serper")

    # ë³‘ë ¬ ì‹¤í–‰
    tavily_result, serper_result = await asyncio.gather(
        tavily_search(),
        serper_search()
    )

    # ê²°ê³¼ ë³‘í•©
    merged = merge_evidence(tavily_result, serper_result)
    return state
```

**íš¨ê³¼**: -1500ms (50% ë‹¨ì¶•)

#### B. LLM ë°°ì¹˜ ì²˜ë¦¬
**í˜„ìž¬**: Link annotationì„ ìˆœì°¨ì ìœ¼ë¡œ 1ê°œì”© ì²˜ë¦¬
**ê°œì„ **: ëª¨ë“  ë§í¬ë¥¼ í•œ ë²ˆì— LLMì—ê²Œ ì „ë‹¬

```python
# research/link_annotator.py
def annotate_links_batch(links: List[str]) -> List[Dict]:
    """ëª¨ë“  ë§í¬ë¥¼ í•œ ë²ˆì— LLMì—ê²Œ ì „ë‹¬"""
    prompt = f"""ë‹¤ìŒ {len(links)}ê°œ ë§í¬ë“¤ì„ ë¶„ì„í•˜ì„¸ìš”:
    {json.dumps(links, ensure_ascii=False)}
    """
    # 1íšŒ LLM í˜¸ì¶œë¡œ ëª¨ë‘ ì²˜ë¦¬
```

**íš¨ê³¼**: -1000ms

---

### 3. ì•„í‚¤í…ì²˜ ê°œì„  (ê³ ë‚œì´ë„)

#### A. LLM ìŠ¤íŠ¸ë¦¬ë°
**í˜„ìž¬**: LLM ì‘ë‹µì„ ê¸°ë‹¤ë¦¼ (blocking)
**ê°œì„ **: ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¦‰ì‹œ í‘œì‹œ

```python
# streamlit_app.py
for chunk in llm.stream(prompt):
    st.write(chunk)  # ì¦‰ì‹œ í‘œì‹œ
```

**íš¨ê³¼**: ì²´ê° ì†ë„ ëŒ€í­ ê°œì„  (ì‹¤ì œ ì‹œê°„ì€ ë™ì¼í•˜ì§€ë§Œ UX í–¥ìƒ)

#### B. ìºì‹±
**í˜„ìž¬**: ë™ì¼í•œ diffë„ ë§¤ë²ˆ ìƒˆë¡œ ë¶„ì„
**ê°œì„ **: ìµœê·¼ ë¶„ì„ ê²°ê³¼ ìºì‹± (Redis/ë©”ëª¨ë¦¬)

```python
@lru_cache(maxsize=100)
def analyze_diff(diff_hash: str):
    ...
```

**íš¨ê³¼**: ìž¬ë¶„ì„ ì‹œ -10ì´ˆ

#### C. Incremental Research
**í˜„ìž¬**: 2íšŒ ê²€ìƒ‰ í›„ HITL â†’ ì¶”ê°€ ê²€ìƒ‰
**ê°œì„ **: ë°±ê·¸ë¼ìš´ë“œì—ì„œ 3ê°œ ê²€ìƒ‰ ì—”ì§„ ëª¨ë‘ ì‹¤í–‰, í•„ìš”ì‹œ ì¦‰ì‹œ ì‚¬ìš©

```python
# ë°±ê·¸ë¼ìš´ë“œ ìž‘ì—…
tavily_future = executor.submit(search_tavily)
serper_future = executor.submit(search_serper)
naver_future = executor.submit(search_naver)

# í•„ìš”í•œ ê²ƒë§Œ ê¸°ë‹¤ë¦¼
result1 = tavily_future.result()
if needs_more:
    result2 = serper_future.result()  # ì´ë¯¸ ì‹¤í–‰ ì¤‘
```

**íš¨ê³¼**: HITL ëŒ€ê¸° ì‹œê°„ -3ì´ˆ

---

### 4. ì¸í”„ë¼ ìµœì í™”

#### A. ë¡œì»¬ LLM ìºì‹œ
```bash
# .env
LANGCHAIN_CACHE=true
```

#### B. HTTP/2 ë©€í‹°í”Œë ‰ì‹±
ê²€ìƒ‰ API í˜¸ì¶œ ì‹œ HTTP/2 ì‚¬ìš©

#### C. CDN/í”„ë¡ì‹œ
ê²€ìƒ‰ ê²°ê³¼ë¥¼ CDNì— ìºì‹± (ë™ì¼ ì¿¼ë¦¬ ìž¬ì‚¬ìš©)

---

## ðŸŽ¯ ê¶Œìž¥ ì ìš© ìˆœì„œ

### Phase 1: Quick Wins (1-2ì‹œê°„)
1. âœ… Streamlit sleep ì œê±° (-1ì´ˆ)
2. âœ… ë„¤ì´ë²„ ê²€ìƒ‰ 5ê°œë¡œ ì¤„ì´ê¸° (-200ms)
3. âœ… ê°„ë‹¨í•œ LLM ìž‘ì—… gpt-3.5-turbo ì‚¬ìš© (-500ms)

**ì˜ˆìƒ ê°œì„ **: -1.7ì´ˆ (12ì´ˆ â†’ 10.3ì´ˆ)

### Phase 2: ë³‘ë ¬í™” (1-2ì¼)
1. âš ï¸ ê²€ìƒ‰ API ë³‘ë ¬ ì‹¤í–‰ (-1.5ì´ˆ)
2. âš ï¸ LLM ë°°ì¹˜ ì²˜ë¦¬ (-1ì´ˆ)

**ì˜ˆìƒ ê°œì„ **: -2.5ì´ˆ (10.3ì´ˆ â†’ 7.8ì´ˆ)

### Phase 3: ì•„í‚¤í…ì²˜ ê°œì„  (1ì£¼)
1. ðŸ”„ LLM ìŠ¤íŠ¸ë¦¬ë° (ì²´ê° ì†ë„ ëŒ€í­ ê°œì„ )
2. ðŸ”„ ìºì‹± (ìž¬ë¶„ì„ ì‹œ -10ì´ˆ)
3. ðŸ”„ Incremental research (HITL -3ì´ˆ)

**ì˜ˆìƒ ê°œì„ **: ì²´ê° ì†ë„ 50% í–¥ìƒ, ìž¬ë¶„ì„ 80% í–¥ìƒ

---

## ðŸ“Š ìµœì¢… ëª©í‘œ

| ì‹œë‚˜ë¦¬ì˜¤ | í˜„ìž¬ | Phase 1 | Phase 2 | Phase 3 |
|---------|------|---------|---------|---------|
| ê¸°ë³¸ (HITL ì—†ìŒ) | 9ì´ˆ | 7.3ì´ˆ | 5.8ì´ˆ | 2-3ì´ˆ (ìŠ¤íŠ¸ë¦¬ë°) |
| HITL í¬í•¨ | 12ì´ˆ | 10.3ì´ˆ | 7.8ì´ˆ | 4-5ì´ˆ (ìŠ¤íŠ¸ë¦¬ë°) |
| ìž¬ë¶„ì„ | 12ì´ˆ | 10.3ì´ˆ | 7.8ì´ˆ | 1-2ì´ˆ (ìºì‹±) |

---

## ðŸ’¡ êµ¬í˜„ ì˜ˆì‹œ

### Phase 1 ì ìš©

```python
# 1. streamlit_app.py:189
# time.sleep(1)  # ì œê±°
st.rerun()

# 2. graph.py:453
results = search_naver(query_ko, max_results=5)  # 10 â†’ 5

# 3. research/naver_query_generator.py:84
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.2)  # gpt-4o-mini â†’ gpt-3.5-turbo
```

### Phase 2 ì ìš© (ë³‘ë ¬í™”)

```python
# graph.pyì— ìƒˆ ë…¸ë“œ ì¶”ê°€
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def research_parallel_node(state: GuardianState) -> GuardianState:
    """Tavilyì™€ Serper ë³‘ë ¬ ì‹¤í–‰"""
    loop = asyncio.get_event_loop()

    def tavily_task():
        return gather_research(state, search_engine="tavily")

    def serper_task():
        return gather_research(state, search_engine="serper")

    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            loop.run_in_executor(executor, tavily_task),
            loop.run_in_executor(executor, serper_task)
        ]
        results = await asyncio.gather(*futures)

    # ê²°ê³¼ ë³‘í•©
    merged = merge_evidence(results[0], results[1])
    state["evidence"] = merged
    state["recheck_count"] = 1  # 2íšŒ ê²€ìƒ‰ ì™„ë£Œ

    return state

# workflow ìˆ˜ì •
workflow.add_node("research_parallel", research_parallel_node)
workflow.add_conditional_edges(
    "soft_llm_judge",
    should_do_research,
    {"research": "research_parallel", "write_report": "write_report"}
)
workflow.add_edge("research_parallel", "observation_validate")
```
