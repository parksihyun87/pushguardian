# ğŸ” PushGuardian ë²¤ì¹˜ë§ˆí¬ ê°€ì´ë“œ

## ê°œìš”

ì´ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œì€ PushGuardianì˜ ì„±ëŠ¥ê³¼ ê²€ìƒ‰ í’ˆì§ˆì„ ì¸¡ì •í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.

## ğŸ“Š ì¸¡ì • ì§€í‘œ

### 1. Performance Metrics (ì„±ëŠ¥ ì§€í‘œ)
- **Total Duration**: ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œê°„ (ms, sec)
- **Search Time**: ìˆœìˆ˜ ê²€ìƒ‰ API í˜¸ì¶œ ì‹œê°„
- **LLM Calls Count**: LLM API í˜¸ì¶œ íšŸìˆ˜
- **Node-by-node Duration**: ê° ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„ ë¶„ì„

### 2. Search Quality Metrics (ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ)
- **Query Length**: ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¨ì–´ ìˆ˜ (ì§§ì„ìˆ˜ë¡ latency ê°ì†Œ)
- **High-Quality Domains Ratio**: ì‹ ë¢°í•  ë§Œí•œ ë„ë©”ì¸ ë¹„ìœ¨ (OWASP, NIST, GitHub ë“±)
- **Spam Filtered Count**: í•„í„°ë§ëœ ìŠ¤íŒ¸ ê²°ê³¼ ìˆ˜
- **Links Found**: ë°œê²¬ëœ Principle/Example ë§í¬ ìˆ˜
- **LLM Assessment**: LLMì´ í‰ê°€í•œ ê²€ìƒ‰ ê²°ê³¼ ì¶©ë¶„ì„±

### 3. Workflow Metrics (ì›Œí¬í”Œë¡œìš° ì§€í‘œ)
- **Research Iterations**: ê²€ìƒ‰ ë°˜ë³µ íšŸìˆ˜ (Tavily â†’ Serper)
- **Tools Used**: ì‚¬ìš©ëœ ê²€ìƒ‰ ì—”ì§„ (tavily, serper, duckduckgo)
- **Decision & Severity**: ìµœì¢… íŒë‹¨ ë° ìœ„í—˜ë„
- **Findings Count**: íƒì§€ëœ ë³´ì•ˆ ì´ìŠˆ ê°œìˆ˜

## ğŸš€ ì‚¬ìš©ë²•

### 1. ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

```bash
# Conda í™˜ê²½ í™œì„±í™”
conda activate p_guard

# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
python run_benchmark.py
```

### 2. ì‹¤í–‰ ê³¼ì •

ë²¤ì¹˜ë§ˆí¬ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ë©ë‹ˆë‹¤:

1. `examples/test_file/` ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  `.txt` íŒŒì¼ ìŠ¤ìº”
2. ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë§ˆë‹¤:
   - LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
   - ê° ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
   - ê²€ìƒ‰ API í˜¸ì¶œ ì¶”ì 
   - LLM í˜¸ì¶œ ì¹´ìš´íŠ¸
   - ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ ìˆ˜ì§‘
3. ëª¨ë“  ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
4. `benchmark_reports/` ë””ë ‰í† ë¦¬ì— ì €ì¥

### 3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (ì´ 9ê°œ)

```
examples/test_file/
â”œâ”€â”€ block.txt                # Hard block (secrets)
â”œâ”€â”€ pass.txt                 # Clean code (pass)
â”œâ”€â”€ medium_risk_dto.txt      # DTO validation issues
â”œâ”€â”€ medium_risk_sql.txt      # SQL injection risk
â”œâ”€â”€ medium_risk_auth.txt     # Auth implementation issues
â”œâ”€â”€ soft_medium_xss.txt      # XSS vulnerability
â”œâ”€â”€ soft_low_style.txt       # Low severity style issues
â”œâ”€â”€ weak_stack_react.txt     # React learning mode
â””â”€â”€ weak_stack_docker.txt    # Docker learning mode
```

## ğŸ“„ ë¦¬í¬íŠ¸ êµ¬ì¡°

ìƒì„±ëœ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ëŠ” ë‹¤ìŒ ì„¹ì…˜ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤:

### 1. Overall Summary (ì „ì²´ ìš”ì•½)
- í‰ê·  ì‹¤í–‰ ì‹œê°„
- í‰ê·  ê²€ìƒ‰ ì‹œê°„
- í‰ê·  LLM í˜¸ì¶œ ìˆ˜
- í‰ê·  ì¿¼ë¦¬ ê¸¸ì´
- Decision/Severity ë¶„í¬

### 2. Detailed Test Case Results (í…ŒìŠ¤íŠ¸ë³„ ìƒì„¸ ê²°ê³¼)
ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë§ˆë‹¤:
- **Performance Metrics**: ì‹¤í–‰ ì‹œê°„, ê²€ìƒ‰ ì‹œê°„, LLM í˜¸ì¶œ
- **Results Summary**: Decision, Severity, Findings, Links
- **Node Execution Timeline**: ê° ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„
- **Search Quality Analysis**:
  - ì¿¼ë¦¬ ë‚´ìš© ë° ê¸¸ì´
  - ê²€ìƒ‰ ì—”ì§„ ë° latency
  - ê²°ê³¼ ê°œìˆ˜ ë° ìŠ¤íŒ¸ í•„í„°ë§
  - ê³ í’ˆì§ˆ ë„ë©”ì¸ ë¹„ìœ¨
  - LLM í‰ê°€ (sufficient/needs refinement)
  - ì‹¤ì œ ë§í¬ ëª©ë¡ (top 3)

### 3. Comparative Analysis (ë¹„êµ ë¶„ì„)
- ëª¨ë“  í…ŒìŠ¤íŠ¸ì˜ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
- ê²€ìƒ‰ ì—”ì§„ ì‚¬ìš© í†µê³„
- ê°€ì¥ ëŠë¦° ì»´í¬ë„ŒíŠ¸ ë¶„ì„

### 4. Performance Optimization Opportunities (ê°œì„  ê¸°íšŒ)
- **Slowest Components**: ê°€ì¥ ëŠë¦° ë…¸ë“œ top 3
- **Query Length Optimization Candidates**: 10ë‹¨ì–´ ì´ìƒì˜ ê¸´ ì¿¼ë¦¬ ëª©ë¡
- **Search Quality Improvements Needed**: ê³ í’ˆì§ˆ ë„ë©”ì¸ ë¹„ìœ¨ 50% ë¯¸ë§Œì¸ ê²€ìƒ‰

### 5. Next Steps (ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­)
- Query Optimization ë°©ì•ˆ
- Search Quality Enhancement ë°©ì•ˆ
- Latency Reduction ë°©ì•ˆ
- Search Engine Selection ìµœì í™”

## ğŸ’¡ ê°œì„  ì „/í›„ ë¹„êµ ë°©ë²•

### 1. Baseline ì¸¡ì •
```bash
# ê°œì„  ì „ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
python run_benchmark.py
# â†’ benchmark_reports/benchmark_20260109_143000.md ìƒì„±
```

### 2. ê°œì„  ì‚¬í•­ ì ìš©
ì˜ˆ: Query optimization, Domain filtering ë“±

### 3. ê°œì„  í›„ ì¸¡ì •
```bash
# ê°œì„  í›„ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
python run_benchmark.py
# â†’ benchmark_reports/benchmark_20260109_150000.md ìƒì„±
```

### 4. ë¹„êµ ë¶„ì„
ë‘ ë¦¬í¬íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ë‹¤ìŒ ì§€í‘œë“¤ì˜ ë³€í™” í™•ì¸:

#### ëª©í‘œ ì§€í‘œ:
- **Query Length**: 30-50% ê°ì†Œ (ëª©í‘œ: í‰ê·  8ë‹¨ì–´ ì´í•˜)
- **Search Time**: 20-30% ê°ì†Œ
- **High-Quality Domain Ratio**: 70% ì´ìƒ
- **Total Duration**: ì „ì²´ ì‹¤í–‰ ì‹œê°„ ë‹¨ì¶•

#### í’ˆì§ˆ ì§€í‘œ:
- **Links Found**: ìœ ì§€ ë˜ëŠ” ì¦ê°€ (í’ˆì§ˆ ì €í•˜ ë°©ì§€)
- **LLM Assessment**: "Sufficient" ë¹„ìœ¨ ì¦ê°€
- **Findings Detection**: ë™ì¼ (ë³´ì•ˆ íƒì§€ ì •í™•ë„ ìœ ì§€)

## ğŸ”§ ì½”ë“œ êµ¬ì¡°

```
pushguardian/benchmark/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ metrics.py              # ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤ ë° ìˆ˜ì§‘ê¸°
â”œâ”€â”€ runner.py               # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ë¡œì§
â””â”€â”€ report_generator.py     # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±

run_benchmark.py            # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```

### ì£¼ìš” í´ë˜ìŠ¤:

#### `MetricsCollector`
ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì‹¤ì‹œê°„ìœ¼ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘:
```python
collector = MetricsCollector()
collector.start_workflow()
collector.start_node("research_tavily")
collector.end_node("research_tavily", state)
collector.add_search_metrics(...)
result = collector.finalize(test_name, test_file, final_state)
```

#### `BenchmarkResult`
í•˜ë‚˜ì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤:
- Performance metrics
- Node-by-node breakdown
- Search quality metrics
- Final results

#### `generate_markdown_report()`
ì—¬ëŸ¬ `BenchmarkResult`ë¥¼ ë°›ì•„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±

## ğŸ“ˆ ì˜ˆìƒ ê°œì„  íš¨ê³¼

### Query Optimization (TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ)
- **Before**: `"prevent secrets in git commits API keys environment variables best practices"` (10 words)
- **After**: `"prevent secrets git commits API keys"` (6 words, 40% ê°ì†Œ)
- **Latency ê°œì„ **: 15-20% ì˜ˆìƒ

### Domain Filtering (site: operator)
- **Before**: ì¼ë°˜ ê²€ìƒ‰ â†’ ìŠ¤íŒ¸ í•„í„°ë§ â†’ ê³ í’ˆì§ˆ ë„ë©”ì¸ 40%
- **After**: `site:owasp.org OR site:github.com` â†’ ê³ í’ˆì§ˆ ë„ë©”ì¸ 85%+
- **Search Quality**: 2ë°° ì´ìƒ ê°œì„ 

### Combined Effect
- **Total Latency**: 25-35% ê°ì†Œ ì˜ˆìƒ
- **Search Quality**: ì‹ ë¢°ë„ ë†’ì€ ë§í¬ ë¹„ìœ¨ 70%+ ë‹¬ì„±
- **User Experience**: ë” ë¹ ë¥´ê³  ì •í™•í•œ ë³´ì•ˆ ê°€ì´ë“œ ì œê³µ

## ğŸ¯ ë²¤ì¹˜ë§ˆí¬ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. ì„±ëŠ¥ íšŒê·€ í…ŒìŠ¤íŠ¸
- ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ì„±ëŠ¥ ì €í•˜ ì—¬ë¶€ í™•ì¸
- CI/CD íŒŒì´í”„ë¼ì¸ì— í†µí•© ê°€ëŠ¥

### 2. A/B í…ŒìŠ¤íŒ…
- ë‹¤ë¥¸ ê²€ìƒ‰ ì „ëµ ë¹„êµ (Tavily vs Serper vs Hybrid)
- Query optimization ì•Œê³ ë¦¬ì¦˜ ë¹„êµ (TF-IDF vs LLM vs Rule-based)

### 3. Cost Analysis
- LLM API í˜¸ì¶œ ìˆ˜ ìµœì í™”
- ê²€ìƒ‰ API ì‚¬ìš©ëŸ‰ ë¶„ì„

### 4. ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
- End-to-end latency ê°œì„ 
- ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ

## ğŸ“ ì£¼ì˜ì‚¬í•­

1. **API í‚¤ í•„ìš”**: `.env` íŒŒì¼ì— `OPENAI_API_KEY`, `TAVILY_API_KEY`, `SERPER_API_KEY` ì„¤ì • í•„ìš”
2. **ì‹¤í–‰ ì‹œê°„**: 9ê°œ í…ŒìŠ¤íŠ¸ Ã— í‰ê·  20-30ì´ˆ = ì•½ 3-5ë¶„ ì†Œìš” ì˜ˆìƒ
3. **ë¹„ìš©**: OpenAI GPT-4o-mini ë° ê²€ìƒ‰ API í˜¸ì¶œ ë¹„ìš© ë°œìƒ
4. **ì¬í˜„ì„±**: ë™ì¼ ì¡°ê±´ì—ì„œ ì‹¤í–‰í•´ì•¼ ê³µì •í•œ ë¹„êµ ê°€ëŠ¥

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•œ í›„:

1. **ë³‘ëª© ì§€ì  íŒŒì•…**: ê°€ì¥ ëŠë¦° ë…¸ë“œ ë° ê²€ìƒ‰ ë‹¨ê³„ í™•ì¸
2. **ê°œì„  ìš°ì„ ìˆœìœ„ ì„ ì •**: Query length, Search quality, Latency ì¤‘ ì§‘ì¤‘í•  ì˜ì—­ ê²°ì •
3. **ê°œì„  ì‚¬í•­ êµ¬í˜„**:
   - [research/gather.py](pushguardian/research/gather.py)ì— query optimization ì¶”ê°€
   - [research/tavily_client.py](pushguardian/research/tavily_client.py), [research/serper_client.py](pushguardian/research/serper_client.py)ì— domain filtering ì¶”ê°€
4. **ì¬ì¸¡ì • ë° ë¹„êµ**: ê°œì„  íš¨ê³¼ ê²€ì¦

---

**ë¬¸ì˜ ë° ê°œì„  ì œì•ˆì€ ì´ìŠˆë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”!**
