"""LLMì„ ì‚¬ìš©í•˜ì—¬ ë„¤ì´ë²„ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±"""

import json
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage


QUERY_GEN_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë³´ì•ˆ ì´ìŠˆì— ëŒ€í•œ í•œê¸€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ë³´ì•ˆ ì´ìŠˆ(Finding)ë¥¼ ë¶„ì„í•˜ì—¬, ë„¤ì´ë²„ì—ì„œ ìœ ìš©í•œ í•œê¸€ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” **ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ì¢‹ì€ ì¿¼ë¦¬ì˜ ì¡°ê±´:**
1. **ë³´ì•ˆ ì¤‘ì‹¬**: ë‹¨ìˆœ ê¸°ëŠ¥ì´ ì•„ë‹Œ ë³´ì•ˆ ì·¨ì•½ì ê³¼ ë°©ì–´ ë°©ë²•ì— ì´ˆì 
2. **êµ¬ì²´ì **: ì¶”ìƒì ì¸ ìš©ì–´ë³´ë‹¤ êµ¬ì²´ì ì¸ ê¸°ìˆ  ìš©ì–´ ì‚¬ìš©
3. **í•œê¸€ ìë£Œ ì¹œí™”ì **: í•œêµ­ ê°œë°œìë“¤ì´ ìì£¼ ì°¾ëŠ” í‚¤ì›Œë“œ ì‚¬ìš©
4. **ì ì ˆí•œ ê¸¸ì´**: 3-6ë‹¨ì–´ ì •ë„

**ì˜ˆì‹œ:**
- XSS ì·¨ì•½ì  â†’ "XSS ê³µê²© ë°©ì–´ HTML ì´ìŠ¤ì¼€ì´í”„"
- SQL Injection â†’ "SQL Injection ë°©ì–´ PreparedStatement"
- DTO ê²€ì¦ â†’ "ì…ë ¥ ê²€ì¦ ë³´ì•ˆ sanitization"

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{
    "query": "ê²€ìƒ‰ ì¿¼ë¦¬ (3-6ë‹¨ì–´)",
    "reason": "ì´ ì¿¼ë¦¬ë¥¼ ì„ íƒí•œ ì´ìœ  (1-2ë¬¸ì¥)"
}
"""


def generate_naver_query(finding_title: str, finding_detail: str, finding_kind: str) -> str:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ Findingì— ìµœì í™”ëœ ë„¤ì´ë²„ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±.

    Args:
        finding_title: Finding ì œëª©
        finding_detail: Finding ìƒì„¸ ì„¤ëª…
        finding_kind: Finding ì¢…ë¥˜ (dto, xss, sql_injection ë“±)

    Returns:
        ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬
    """
    prompt = f"""ë‹¤ìŒ ë³´ì•ˆ ì´ìŠˆì— ëŒ€í•œ í•œê¸€ ìë£Œë¥¼ ì°¾ê¸° ìœ„í•œ ë„¤ì´ë²„ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ë³´ì•ˆ ì´ìŠˆ:**
- ì¢…ë¥˜: {finding_kind}
- ì œëª©: {finding_title}
- ìƒì„¸: {finding_detail[:300]}

ë„¤ì´ë²„ì—ì„œ **ë³´ì•ˆ ê´€ì ì˜ ì‹¤ìš©ì ì¸ í•œê¸€ ìë£Œ**ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ìµœì ì˜ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´).
"""

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)

    messages = [
        SystemMessage(content=QUERY_GEN_SYSTEM_PROMPT),
        HumanMessage(content=prompt),
    ]

    try:
        response = llm.invoke(messages)
        content = response.content.strip()

        # JSON ì¶”ì¶œ
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()

        result = json.loads(content)
        query = result.get("query", "")
        reason = result.get("reason", "")

        print(f"ğŸ” LLM ìƒì„± ì¿¼ë¦¬: '{query}'")
        print(f"   ì´ìœ : {reason}")

        return query if query else "ì›¹ ë³´ì•ˆ ì…ë ¥ ê²€ì¦"  # í´ë°±

    except Exception as e:
        print(f"âš ï¸ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±: ê°„ë‹¨í•œ ì¿¼ë¦¬ ìƒì„±
        if "xss" in finding_detail.lower():
            return "XSS ë°©ì–´ ë°©ë²•"
        elif "sql" in finding_detail.lower():
            return "SQL Injection ë°©ì–´"
        else:
            return f"{finding_kind} ë³´ì•ˆ"
