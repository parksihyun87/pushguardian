"""Streamlit frontend for PushGuardian (alternative to FastAPI HTML)."""

import streamlit as st
from pathlib import Path
import subprocess
from pushguardian.graph import run_guardian_stream, build_graph
from pushguardian.repo_context import RepoContext
from langgraph.checkpoint.memory import MemorySaver

st.set_page_config(page_title="PushGuardian", page_icon="ğŸ›¡ï¸", layout="wide")

st.title("ğŸ›¡ï¸ PushGuardian - Git Diff ë³´ì•ˆ ë¶„ì„ê¸°")
st.markdown(
    """
Git diffë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ë³´ì•ˆ ì´ìŠˆì™€ ëª¨ë²” ì‚¬ë¡€ ìœ„ë°˜**ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.  
ì•„ë˜ì— diff í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ ë„£ê±°ë‚˜ diff íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.
"""
)

# Example files mapping
EXAMPLE_FILES = {
    "-- ì˜ˆì‹œë¥¼ ì„ íƒí•˜ì„¸ìš” --": None,
    "ğŸš¨ í•˜ë“œ ë¸”ë¡ (ì¹˜ëª…ì  ë³´ì•ˆ ìœ„í—˜)": "examples/test_file/block.txt",
    "ğŸŸ  ì¤‘ê°„ ìœ„í—˜ (LLM ì†Œí”„íŠ¸ íŒì •)": "examples/test_file/soft_medium_xss.txt",
    "ğŸŸ¡ ë‚®ì€ ìœ„í—˜ (ì½”ë“œ ìŠ¤íƒ€ì¼/ì„±ëŠ¥)": "examples/test_file/soft_low_style.txt",
    "ğŸ“– ì•½ì  ìŠ¤íƒ (í•™ìŠµ ëª¨ë“œ)": "examples/test_file/weak_stack_docker.txt",
    "âœ… ê¹¨ë—í•œ ì½”ë“œ (í†µê³¼ ì˜ˆì‹œ)": "examples/test_file/pass.txt",
    "âš ï¸ (beta) ì¶©ëŒ ìœ„í—˜": "examples/test_file/conflict_risk.txt",
}

# Input method selection
input_method = st.radio(
    "ì…ë ¥ ë°©ì‹",
    [
        "Diff í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°",
        "Git ë ˆí¬ ê²½ë¡œ ì§€ì • (ë¡œì»¬ì—ì„œ ì»¤ë°‹ ë¶„ì„)",
    ],
)

diff_text = None

# Example selector (only for "Diff í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°" mode)
if input_method == "Diff í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°":
    st.markdown("**ë¹ ë¥¸ í…ŒìŠ¤íŠ¸:** PushGuardian ë™ì‘ì„ ë³´ê¸° ìœ„í•´ ì˜ˆì œ diffë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    example_choice = st.selectbox(
        "ì˜ˆì œ ë¶ˆëŸ¬ì˜¤ê¸°",
        options=list(EXAMPLE_FILES.keys()),
        help="ì˜ˆì œë¥¼ ì„ íƒí•˜ë©´ ì•„ë˜ í…ìŠ¤íŠ¸ ì˜ì—­ì— ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.",
    )

    # Load example file if selected
    example_content = ""
    is_conflict_example = (example_choice == "âš ï¸ (beta) ì¶©ëŒ ìœ„í—˜")

    if example_choice != "-- ì˜ˆì‹œë¥¼ ì„ íƒí•˜ì„¸ìš” --":
        example_path = Path(EXAMPLE_FILES[example_choice])
        if example_path.exists():
            example_content = example_path.read_text(encoding="utf-8")
        else:
            st.warning(f"âš ï¸ ì˜ˆì œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {example_path}")

    # Special UI for conflict example (dual diff input)
    if is_conflict_example and example_content:
        st.info("ğŸ§ª **beta ê¸°ëŠ¥**: Merge Conflict ì˜ˆì¸¡ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ë‚´ ë³€ê²½ì‚¬í•­ê³¼ Main ë¸Œëœì¹˜ ë³€ê²½ì‚¬í•­ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.")

        # Parse example file into two parts
        if "=== MY DIFF ===" in example_content and "=== BASE DIFF" in example_content:
            # Split by any BASE DIFF marker (with or without "(origin/main)")
            import re
            parts = re.split(r"=== BASE DIFF[^\n]*===", example_content)
            my_diff_example = parts[0].replace("=== MY DIFF ===", "").strip()
            base_diff_example = parts[1].strip() if len(parts) > 1 else ""
        else:
            my_diff_example = example_content
            base_diff_example = ""

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ“ ë‚´ ë³€ê²½ì‚¬í•­ (My Diff)")
            my_diff = st.text_area(
                "My Diff",
                value=my_diff_example,
                height=300,
                label_visibility="collapsed"
            )
        with col2:
            st.markdown("### ğŸŒ Main ë¸Œëœì¹˜ ë³€ê²½ì‚¬í•­")
            base_diff = st.text_area(
                "Base Diff",
                value=base_diff_example,
                height=300,
                label_visibility="collapsed"
            )

        # Combine into special format for backend
        diff_text = f"=== MY DIFF ===\n{my_diff}\n\n=== BASE DIFF ===\n{base_diff}"

        # Enable conflict detection for this analysis
        st.session_state["enable_conflict_detection"] = True
    else:
        # Normal single diff input
        diff_text = st.text_area(
            "Git Diff ë‚´ìš©",
            value=example_content,
            height=300,
            placeholder="ì—¬ê¸°ì— git diff ì¶œë ¥ ê²°ê³¼ë¥¼ ë¶™ì—¬ ë„£ì–´ ì£¼ì„¸ìš”...",
            help="ì˜ˆ: git diff HEAD~1 HEAD",
        )
        st.session_state["enable_conflict_detection"] = False
elif input_method == "Git ë ˆí¬ ê²½ë¡œ ì§€ì • (ë¡œì»¬ì—ì„œ ì»¤ë°‹ ë¶„ì„)":
    st.info(
        "ì•„ì§ ì›ê²©(origin/main)ìœ¼ë¡œ í‘¸ì‹œë˜ì§€ ì•Šì€ ì»¤ë°‹ ë²”ìœ„ ì „ì²´ì— ëŒ€í•œ diffë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. "
        "ì•„ë˜ì— Git ë ˆí¬ì§€í† ë¦¬ ë£¨íŠ¸ ê²½ë¡œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."
    )

    repo_path = st.text_input(
        "Git ë ˆí¬ì§€í† ë¦¬ ê²½ë¡œ",
        value="",
        placeholder="ì˜ˆ: C:/workspace/my-project ë˜ëŠ” . (í˜„ì¬ í´ë”)",
        help="ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ìƒëŒ€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”. '.'ì€ Streamlitì„ ì‹¤í–‰í•œ í´ë”ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
    )

    base_ref = st.text_input("ë¹„êµ ê¸°ì¤€ ë¸Œëœì¹˜/íƒœê·¸ (ê¸°ë³¸: origin/main)", value="origin/main")

    if st.button("ğŸ“Œ ë¯¸í‘¸ì‹œ ì»¤ë°‹ ì „ì²´ diff ê°€ì ¸ì˜¤ê¸°"):
        try:
            repo = RepoContext(repo_path)
            ahead = repo.ahead_count(base_ref=base_ref, head_ref="HEAD")
            if ahead <= 0:
                st.info("í˜„ì¬ ë¸Œëœì¹˜ëŠ” ê¸°ì¤€ ref ë³´ë‹¤ ì•ì„  ì»¤ë°‹ì´ ì—†ìŠµë‹ˆë‹¤. (ë¯¸í‘¸ì‹œ ì»¤ë°‹ ì—†ìŒ)")
                st.session_state["loaded_diff"] = None
            else:
                fetched_diff = repo.diff_last_n_commits(ahead, head_ref="HEAD")
                st.session_state["loaded_diff"] = fetched_diff
                preview = fetched_diff[:1500] + ("..." if len(fetched_diff) > 1500 else "")
                st.success(f"ë¯¸í‘¸ì‹œ ì»¤ë°‹ {ahead}ê°œì— ëŒ€í•œ diffë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                st.text_area("Git Diff ë¯¸ë¦¬ë³´ê¸°", preview, height=300, disabled=True)
        except Exception as e:
            st.error(f"ë ˆí¬ì§€í† ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.session_state["loaded_diff"] = None

    # Set diff_text from session state
    if "loaded_diff" in st.session_state and st.session_state["loaded_diff"]:
        diff_text = st.session_state["loaded_diff"]

# Node name mapping for user-friendly display
NODE_NAMES = {
    "load_config": "âš™ï¸ ì„¤ì • ë¡œë”© ì¤‘",
    "scope_classify": "ğŸ” íŒŒì¼ íƒ€ì… ë° ìŠ¤íƒ ë¶„ë¥˜ ì¤‘",
    "conflict_detect": "âš ï¸ ì¶©ëŒ ê°ì§€ ì¤‘ (beta)",
    "conflict_analyze": "ğŸ”¬ ì¶©ëŒ ë¶„ì„ ì¤‘ (beta)",
    "hard_policy_check": "ğŸš¨ í•˜ë“œ ë³´ì•ˆ ê·œì¹™ ê²€ì‚¬ ì¤‘",
    "soft_llm_judge": "ğŸ¤– LLM ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ ì¤‘",
    "research_tavily": "ğŸ” Tavilyë¡œ ë³´ì•ˆ ìë£Œ ê²€ìƒ‰ ì¤‘",
    "research_serper": "ğŸ” Serperë¡œ ì‹¬í™” ê²€ìƒ‰ ì¤‘",
    "observation_validate": "ğŸ§  LLMì´ ë¦¬ì„œì¹˜ í’ˆì§ˆ í‰ê°€ ì¤‘",
    "human_approval": "â¸ï¸  ì‚¬ëŒì˜ ìŠ¹ì¸ ëŒ€ê¸° ì¤‘",
    "research_naver": "ğŸ” ë„¤ì´ë²„ë¡œ í•œê¸€ ìë£Œ ê²€ìƒ‰ ì¤‘",
    "write_report": "ğŸ“ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘",
    "persist_report": "ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ ì¤‘",
}

# Initialize session state for HITL
if "hitl_graph" not in st.session_state:
    st.session_state.hitl_graph = None
if "hitl_config" not in st.session_state:
    st.session_state.hitl_config = None
if "hitl_waiting" not in st.session_state:
    st.session_state.hitl_waiting = False
if "hitl_state" not in st.session_state:
    st.session_state.hitl_state = None
if "hitl_processing" not in st.session_state:
    st.session_state.hitl_processing = False
if "hitl_processing_type" not in st.session_state:
    st.session_state.hitl_processing_type = None

# HITL processing - ì‹¤ì œ ê·¸ë˜í”„ ì‹¤í–‰
if st.session_state.hitl_processing:
    st.warning("â¸ï¸  **í•œê¸€ ìë£Œ ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤ (HITL)**")
    st.markdown("---")

    processing_type = st.session_state.hitl_processing_type
    if processing_type == "search_naver":
        st.info("ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ì„ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    else:
        st.info("â­ï¸ í˜„ì¬ ìë£Œë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

    progress_placeholder = st.empty()

    graph = st.session_state.hitl_graph
    config = st.session_state.hitl_config

    try:
        # ê·¸ë˜í”„ ì¬ê°œ
        final_state = None
        node_count = 0
        for chunk in graph.stream(None, config=config):
            for node_name, current_state in chunk.items():
                node_count += 1
                final_state = current_state
                friendly_name = NODE_NAMES.get(node_name, f"{node_name} ì²˜ë¦¬ ì¤‘")
                progress_placeholder.info(f"â³ {friendly_name} (ë…¸ë“œ #{node_count})")

                # ë””ë²„ê¹…: ë„¤ì´ë²„ ê²€ìƒ‰ í›„ ë§í¬ ìˆ˜ í™•ì¸
                if node_name == "research_naver" and "evidence" in current_state:
                    ev = current_state["evidence"]
                    print(f"[DEBUG] research_naver ì™„ë£Œ - ì›ì¹™: {len(ev.principle_links)}, ì˜ˆì‹œ: {len(ev.example_links)}")
                elif node_name == "write_report" and "evidence" in current_state:
                    ev = current_state["evidence"]
                    print(f"[DEBUG] write_report ì™„ë£Œ - ì›ì¹™: {len(ev.principle_links)}, ì˜ˆì‹œ: {len(ev.example_links)}")

        progress_placeholder.empty()

        if final_state:
            if processing_type == "search_naver":
                # ìµœì¢… ìƒíƒœì˜ evidence í™•ì¸
                if "evidence" in final_state:
                    ev = final_state["evidence"]
                    st.success(f"âœ… ë„¤ì´ë²„ ê²€ìƒ‰ ì™„ë£Œ! (ì´ {node_count}ê°œ ë…¸ë“œ ì‹¤í–‰)")
                    st.info(f"ğŸ“Š ì—…ë°ì´íŠ¸ëœ ë§í¬: ì›ì¹™ {len(ev.principle_links)}ê°œ, ì˜ˆì‹œ {len(ev.example_links)}ê°œ")
                    print(f"[STREAMLIT] final_state ì €ì¥ ì „ - ì›ì¹™: {len(ev.principle_links)}, ì˜ˆì‹œ: {len(ev.example_links)}")
                else:
                    st.success(f"âœ… ë„¤ì´ë²„ ê²€ìƒ‰ ì™„ë£Œ! (ì´ {node_count}ê°œ ë…¸ë“œ ì‹¤í–‰)")
            else:
                st.success("âœ… ë¦¬í¬íŠ¸ ì‘ì„± ì™„ë£Œ!")

            # ìƒíƒœ ì €ì¥ ì „ì— í•œë²ˆ ë” í™•ì¸
            print(f"[STREAMLIT] final_stateë¥¼ session_state.final_resultì— ì €ì¥í•©ë‹ˆë‹¤")
            st.session_state.final_result = final_state
            st.session_state.hitl_processing = False
            st.session_state.hitl_processing_type = None
            st.rerun()

    except Exception as e:
        st.error(f"ì¬ê°œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        st.code(traceback.format_exc())
        st.session_state.hitl_processing = False
        st.session_state.hitl_processing_type = None

# HITL ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ê²½ìš° ìŠ¹ì¸ í™”ë©´ í‘œì‹œ
elif st.session_state.hitl_waiting and st.session_state.hitl_state:
    st.warning("â¸ï¸  **í•œê¸€ ìë£Œ ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤ (HITL)**")
    st.markdown("---")

    state = st.session_state.hitl_state
    evidence = state.get("evidence")

    st.info(f"""
    **í˜„ì¬ ìˆ˜ì§‘ëœ ìë£Œ:**
    - ì›ì¹™ ë§í¬: {len(evidence.principle_links) if evidence else 0}ê°œ
    - ì˜ˆì‹œ ë§í¬: {len(evidence.example_links) if evidence else 0}ê°œ

    í•œê¸€ ìë£Œê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„¤ì´ë²„ ê²€ìƒ‰ APIë¡œ í•œê¸€ ìë£Œë¥¼ ì¶”ê°€ë¡œ ê²€ìƒ‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
    """)

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ ì¶”ê°€", type="primary", use_container_width=True):
            # ì‚¬ìš©ìê°€ ë„¤ì´ë²„ ê²€ìƒ‰ì„ ì„ íƒ
            st.session_state.hitl_state["human_decision"] = "search_naver"
            st.session_state.hitl_waiting = False

            # ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸
            graph = st.session_state.hitl_graph
            config = st.session_state.hitl_config
            graph.update_state(config, st.session_state.hitl_state)

            # Processing í”Œë˜ê·¸ ì„¤ì •í•˜ê³  ì¦‰ì‹œ rerun
            st.session_state.hitl_processing = True
            st.session_state.hitl_processing_type = "search_naver"
            st.rerun()

    with col2:
        if st.button("â­ï¸ ê±´ë„ˆë›°ê³  ê³„ì†", use_container_width=True):
            # í˜„ì¬ ìë£Œë¡œ ê³„ì† ì§„í–‰
            st.session_state.hitl_state["human_decision"] = "skip"
            st.session_state.hitl_waiting = False

            # ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸
            graph = st.session_state.hitl_graph
            config = st.session_state.hitl_config
            graph.update_state(config, st.session_state.hitl_state)

            # Processing í”Œë˜ê·¸ ì„¤ì •í•˜ê³  ì¦‰ì‹œ rerun
            st.session_state.hitl_processing = True
            st.session_state.hitl_processing_type = "skip"
            st.rerun()

# Analyze button
elif st.button("ğŸ” Diff ë¶„ì„í•˜ê¸°", type="primary"):
    if not diff_text or not diff_text.strip():
        st.error("ë¶„ì„í•  diff ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    else:
        # Reset HITL state
        st.session_state.hitl_waiting = False
        st.session_state.hitl_state = None
        if "final_result" in st.session_state:
            del st.session_state.final_result

        # Create placeholder for progress
        progress_placeholder = st.empty()
        status_container = st.container()

        try:
            state = None

            # Build graph with HITL support
            checkpointer = MemorySaver()
            thread_id = "web_session_1"
            config = {"configurable": {"thread_id": thread_id}}

            graph = build_graph(checkpointer=checkpointer)
            st.session_state.hitl_graph = graph
            st.session_state.hitl_config = config

            initial_state = {
                "diff_text": diff_text,
                "mode": "web",
                "repo_root": None,
            }

            # Enable conflict detection if flag is set
            if st.session_state.get("enable_conflict_detection", False):
                initial_state["config"] = {
                    "conflict_detection": {
                        "enabled": True,
                        "base_branch": "origin/main",
                        "auto_fetch": False
                    }
                }

            # Stream execution with progress updates
            interrupted = False
            for chunk in graph.stream(initial_state, config=config):
                for node_name, current_state in chunk.items():
                    state = current_state

                    # Display current node
                    friendly_name = NODE_NAMES.get(node_name, f"{node_name} ì²˜ë¦¬ ì¤‘")
                    progress_placeholder.info(f"â³ ë¶„ì„ ì¤‘... {friendly_name}")

                    # Check if we hit human_approval node
                    if node_name == "human_approval" or current_state.get("human_approval_needed"):
                        # ì¸í„°ëŸ½íŠ¸ ë°œìƒ: HITL í•„ìš”
                        st.session_state.hitl_waiting = True
                        st.session_state.hitl_state = current_state
                        interrupted = True
                        break

                if interrupted:
                    break

            # Clear progress indicator
            progress_placeholder.empty()

            if interrupted:
                # HITL ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜ - í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                st.rerun()
            elif state is None:
                st.error("Workflow did not produce a final state")
            else:
                # ì •ìƒ ì™„ë£Œ - ê²°ê³¼ í‘œì‹œ
                st.session_state.final_result = state
                st.rerun()

        except Exception as e:
            progress_placeholder.empty()
            st.error(f"ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

# ê²°ê³¼ í‘œì‹œ (final_resultê°€ ìˆì„ ë•Œ)
if "final_result" in st.session_state and st.session_state.final_result:
    state = st.session_state.final_result

    # LangSmith URLì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ìƒì„± (HITL ì¬ê°œ í›„ì—ëŠ” ì—†ì„ ìˆ˜ ìˆìŒ)
    if "langsmith_url" not in state or not state["langsmith_url"]:
        import os
        langsmith_enabled = os.getenv("LANGCHAIN_TRACING_V2") == "true"
        if langsmith_enabled:
            project_name = os.getenv("LANGCHAIN_PROJECT", "default")
            state["langsmith_url"] = f"https://smith.langchain.com/o/default/projects/p/{project_name}"

    # ë””ë²„ê¹…: í˜„ì¬ í‘œì‹œë˜ëŠ” ìƒíƒœì˜ ë§í¬ ê°œìˆ˜ í™•ì¸
    if "evidence" in state:
        ev = state["evidence"]
        print(f"[STREAMLIT DISPLAY] í™”ë©´ì— í‘œì‹œ ì¤‘ - ì›ì¹™: {len(ev.principle_links)}, ì˜ˆì‹œ: {len(ev.example_links)}")

    # Display results
    col1, col2, col3 = st.columns(3)

    with col1:
        decision_color = "ğŸ”´" if state["decision"] == "block" else "ğŸŸ¢"
        decision_ko = {
            "allow": "í—ˆìš©",
            "block": "ì°¨ë‹¨",
            "override": "ì˜¤ë²„ë¼ì´ë“œ"
        }.get(state["decision"].lower(), state["decision"].upper())
        st.metric("ê²°ì •", f"{decision_color} {decision_ko}")

    with col2:
        severity_ko = {
            "low": "ë‚®ìŒ",
            "medium": "ì¤‘ê°„",
            "high": "ë†’ìŒ",
            "critical": "ì‹¬ê°"
        }.get(state["severity"].lower(), state["severity"].upper())
        st.metric("ì‹¬ê°ë„", severity_ko)

    with col3:
        st.metric("ìœ„í—˜ ì ìˆ˜", f"{state['risk_score']:.2f}/1.00")

    # Findings
    all_findings = state["hard_findings"] + state["soft_findings"]

    if all_findings:
        st.subheader("ğŸ” ë°œê²¬ëœ ì´ìŠˆ")
        for i, finding in enumerate(all_findings, 1):
            severity_emoji = {
                "low": "ğŸŸ¡",
                "medium": "ğŸŸ ",
                "high": "ğŸ”´",
                "critical": "ğŸš¨",
            }.get(finding.severity, "âšª")

            finding_severity_ko = {
                "low": "ë‚®ìŒ",
                "medium": "ì¤‘ê°„",
                "high": "ë†’ìŒ",
                "critical": "ì‹¬ê°"
            }.get(finding.severity.lower(), finding.severity.upper())

            with st.expander(
                f"{severity_emoji} [{finding_severity_ko}] {finding.title}"
            ):
                st.markdown(f"**ìœ í˜•:** `{finding.kind}`")
                st.markdown(f"**ì‹ ë¢°ë„:** {finding.confidence:.0%}")
                st.markdown(f"**ìƒì„¸ ì„¤ëª…:**\n{finding.detail}")
                st.markdown(f"**ì¦‰ì‹œ ìˆ˜ì • ê°€ì´ë“œ:**\n```\n{finding.fix_now}\n```")
    else:
        st.success("âœ… ì¹˜ëª…ì ì¸ ë³´ì•ˆ ì´ìŠˆê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

    # Conflict Warnings Section (beta)
    conflict_warnings = state.get("conflict_warnings", [])
    if conflict_warnings:
        st.divider()
        st.subheader("âš ï¸ ë³‘í•© ì¶©ëŒ ì˜ˆì¸¡ (beta)")
        st.info(
            f"ğŸ” {len(conflict_warnings)}ê°œ íŒŒì¼ì—ì„œ ë³‘í•© ì¶©ëŒ ê°€ëŠ¥ì„±ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. "
            "ë‚´ ë³€ê²½ì‚¬í•­ê³¼ base branch ë³€ê²½ì‚¬í•­ì´ ê²¹ì¹©ë‹ˆë‹¤."
        )

        for i, warning in enumerate(conflict_warnings, 1):
            # Conflict type emoji mapping
            conflict_emoji = {
                "routing": "ğŸ”€",
                "config": "âš™ï¸",
                "refactoring": "ğŸ”§",
                "semantic_duplicate": "ğŸ“‹",
                "unknown": "â“"
            }.get(warning.conflict_type, "âš ï¸")

            # Conflict probability display
            prob = warning.conflict_probability
            prob_display = f"{prob:.0%}"
            prob_badge = "ğŸ”´" if prob >= 0.7 else "ğŸŸ " if prob >= 0.4 else "ğŸŸ¡"

            # Recommendation mapping
            recommendation_ko = {
                "keep_both": "ì–‘ìª½ ëª¨ë‘ ìœ ì§€",
                "choose_one": "í•˜ë‚˜ ì„ íƒ",
                "manual_merge": "ìˆ˜ë™ ë³‘í•© í•„ìš”"
            }.get(warning.recommendation, warning.recommendation)

            with st.expander(
                f"{conflict_emoji} {warning.file_path} - {prob_badge} {prob_display}",
                expanded=(i == 1)  # First one expanded
            ):
                st.markdown(f"**ì¶©ëŒ ìœ í˜•:** `{warning.conflict_type}`")
                st.markdown(f"**ì¶©ëŒ í™•ë¥ :** {prob_display}")
                st.markdown(f"**ê¶Œì¥ ì¡°ì¹˜:** {recommendation_ko}")
                st.markdown(f"**ë¼ì¸ ê²¹ì¹¨:** {'ì˜ˆ' if warning.line_overlap else 'ì•„ë‹ˆì˜¤'}")
                st.markdown(f"\n**ë¶„ì„:**\n{warning.advice_ko}")

                # Merge suggestion
                st.markdown("---")
                st.markdown("### ğŸ’¡ ê¶Œì¥ ë³‘í•© ë°©ë²•")
                st.markdown(warning.merge_suggestion_ko)

    # Weak Stack Learning Section (separate from findings)
    if state.get("weak_stack_touched") and state.get("learning_points"):
        st.divider()
        st.subheader("ğŸ“– í•™ìŠµ: ì•½ì  ìŠ¤íƒ ê°ì§€ë¨")
        st.warning(
            f"âš ï¸ ì´ ë³€ê²½ì‚¬í•­ì€ ì‚¬ìš©ìê°€ ì•½ì  ìŠ¤íƒìœ¼ë¡œ ì§€ì •í•œ **{', '.join(state['weak_stack_touched'])}** "
            f"ì˜ì—­ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” í•´ë‹¹ ì½”ë“œì™€ ê´€ë ¨ëœ ê¸°ë³¸ ê°œë…ë“¤ì…ë‹ˆë‹¤:"
        )

        for lp in state["learning_points"]:
            # Learning points always use ğŸŸ¡ to distinguish from security findings
            with st.expander(f"ğŸŸ¡ {lp.get('concept', 'ì•Œ ìˆ˜ ì—†ëŠ” ê°œë…')}", expanded=True):
                st.markdown(f"**ìŠ¤íƒ:** `{lp.get('stack', 'general')}`")
                st.markdown(f"**ì˜ë¯¸:** {lp.get('detail', 'ìƒì„¸ ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.')}")

    # Full report
    st.divider()
    st.subheader("ğŸ“„ ì „ì²´ ë¦¬í¬íŠ¸")
    st.markdown(state["report_md"])

    # Developer debug info
    with st.expander("ğŸ”§ ê°œë°œììš© ë””ë²„ê·¸ ì •ë³´"):
        # LangSmith Trace Link (if available)
        if state.get("langsmith_url"):
            st.markdown("### ğŸ”— LangSmith ë””ë²„ê¹… (ê°œì¸ìš©)")
            st.info("âš ï¸ LangSmithì—ì„œ ìƒì„¸ LangGraph ì‹¤í–‰ ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ì¸ LangSmith ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
            st.markdown(f"ğŸ” [LangSmith í”„ë¡œì íŠ¸ ë³´ê¸°]({state['langsmith_url']})")
            st.caption("í”„ë¡œì íŠ¸ í˜ì´ì§€ì—ì„œ ìµœê·¼ ì‹¤í–‰ ê¸°ë¡ì„ í™•ì¸í•˜ì„¸ìš”. ê°€ì¥ ìµœì‹  traceê°€ ë°©ê¸ˆ ì‹¤í–‰ëœ ë¶„ì„ì…ë‹ˆë‹¤.")
            st.divider()

        st.markdown("### ğŸ“Š ë¦¬ì„œì¹˜ ìš”ì•½")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ë¦¬ì„œì¹˜ ë°˜ë³µ íšŸìˆ˜", state["evidence"].research_iterations)
        with col2:
            st.metric("ì›ë¦¬ ë¬¸ì„œ ë§í¬ ìˆ˜", len(state["evidence"].principle_links))
        with col3:
            st.metric("ì˜ˆì œ ë§í¬ ìˆ˜", len(state["evidence"].example_links))

        # ì‹¤ì œ ë§í¬ ëª©ë¡ í‘œì‹œ
        st.markdown("### ğŸ”— ìˆ˜ì§‘ëœ ë§í¬")

        if state["evidence"].principle_links:
            st.markdown("**ğŸ“š ì›ì¹™ ë§í¬ (Principle Links):**")
            for i, link in enumerate(state["evidence"].principle_links, 1):
                st.markdown(f"{i}. {link}")
        else:
            st.info("ì›ì¹™ ë§í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("")  # ê°„ê²©

        if state["evidence"].example_links:
            st.markdown("**ğŸ’¡ ì˜ˆì‹œ ë§í¬ (Example Links):**")
            for i, link in enumerate(state["evidence"].example_links, 1):
                st.markdown(f"{i}. {link}")
        else:
            st.info("ì˜ˆì‹œ ë§í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("### ğŸ” ì‚¬ìš©ëœ ê²€ìƒ‰ ì¿¼ë¦¬")
        if state["evidence"].search_queries:
            for i, query in enumerate(state["evidence"].search_queries, 1):
                st.code(f"{i}. {query}", language="text")
        else:
            st.info("ê¸°ë¡ëœ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("### ğŸ› ï¸ ì‚¬ìš©ëœ ë„êµ¬")
        if state["evidence"].tools_used:
            st.write(", ".join(state["evidence"].tools_used))
        else:
            st.info("ê¸°ë¡ëœ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("### ğŸ¤– LLM Observation (ì—ì´ì „íŠ¸ ë™ì‘ ë¡œê·¸)")
        if state["evidence"].llm_observations:
            for i, obs in enumerate(state["evidence"].llm_observations, 1):
                st.markdown(f"**Observation #{i}** (Iteration {obs.get('iteration', '?')})")
                st.json(obs)
        else:
            st.info("ê¸°ë¡ëœ LLM Observationì´ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("### ğŸ“ ë‚´ë¶€ ë…¸íŠ¸ (ì—ì´ì „íŠ¸ ReAct ì‚¬ê³  ê³¼ì •)")
        if state["evidence"].notes:
            st.text_area("ë¦¬ì„œì¹˜ ë…¸íŠ¸", state["evidence"].notes, height=150, disabled=True, key="internal_notes")
        else:
            st.info("ë‚´ë¶€ ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # Download button
    st.download_button(
        label="ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (Markdown)",
        data=state["report_md"],
        file_name="pushguardian_report.md",
        mime="text/markdown",
    )

# Footer
st.markdown("---")
st.markdown("*[LangGraph](https://langchain-ai.github.io/langgraph/) & Streamlitìœ¼ë¡œ ì œì‘ë¨*")
